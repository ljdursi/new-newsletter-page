---
layout: post
title: A framework to assess the quality and impact of bioinformatics training across ELIXIR -
date: 2020-07-31
<<<<<<< HEAD
issue_number: 35
=======
>>>>>>> 0a34fe0... First go at item pages
original_url: https://www.researchcomputingteams.org/newsletter_issues/0035
tags: ['training_researchers']
priority: 3
---

<!-- markdownlint-disable MD033 -->
<!-- markdownlint-disable MD041 -->
<!-- markdownlint-disable MD049 -->

[A framework to assess the quality and impact of bioinformatics training across ELIXIR](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007976) -
Kim T. Gurwitz *et al*.

Speaking of training - A lot of us run online training programmes, but fewer have systematic ways of following up and quantifying how it impacted on trainee's success in their research. In this paper, the [ELIXIR](https://elixir-europe.org) project - an EU-wide set of life sciences resources - reports on their quality and impact of training courses with four years of self-reported survey data of almost three thousand trainees.

The post-instruction survey information is interesting, but more interesting is the followup results six months and longer afterwards, to get self-reported measures on how well the training affected the researchers' ability to do their work. Getting people to respond is a challenge - they had an 11% response rate - but given how simple these sort of automation steps are with CMSes or mail management software, I'm surprised it isn't done more often.
None of this replaces educational assessments (e.g. pre- and post-quizzes) of the training material itself, which would be very course specific; nor is it fine-grained enough information to be actionable (although open text fields could give useful qualitative feedback). But having this sort of long term data with research-reported responses about impact would be very useful to have when trying to secure funding for training programmes.